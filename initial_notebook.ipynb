{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577816fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:39.499654Z",
     "start_time": "2023-05-08T00:07:38.859511Z"
    }
   },
   "outputs": [],
   "source": [
    "import abstracts_analysis as aa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc24622d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:39.722612Z",
     "start_time": "2023-05-08T00:07:39.501051Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,\\\n",
    "                                            CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb85298d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:40.163978Z",
     "start_time": "2023-05-08T00:07:39.723675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  ../data/arxiv_data_210930-054931.csv\n"
     ]
    }
   ],
   "source": [
    "df = aa.load_to_df(choice='long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da21d17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:40.173907Z",
     "start_time": "2023-05-08T00:07:40.165720Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = list(df['abstracts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3149ad4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:40.189248Z",
     "start_time": "2023-05-08T00:07:40.175292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Graph neural networks (GNNs) have been widely used to learn vector\\nrepresentation of graph-structured data and achieved better task performance\\nthan conventional methods. The foundation of GNNs is the message passing\\nprocedure, which propagates the information in a node to its neighbors. Since\\nthis procedure proceeds one step per layer, the range of the information\\npropagation among nodes is small in the lower layers, and it expands toward the\\nhigher layers. Therefore, a GNN model has to be deep enough to capture global\\nstructural information in a graph. On the other hand, it is known that deep GNN\\nmodels suffer from performance degradation because they lose nodes' local\\ninformation, which would be essential for good model performance, through many\\nmessage passing steps. In this study, we propose multi-level attention pooling\\n(MLAP) for graph-level classification tasks, which can adapt to both local and\\nglobal structural information in a graph. It has an attention pooling layer for\\neach message passing step and computes the final graph representation by\\nunifying the layer-wise graph representations. The MLAP architecture allows\\nmodels to utilize the structural information of graphs with multiple levels of\\nlocalities because it preserves layer-wise information before losing them due\\nto oversmoothing. Results of our experiments show that the MLAP architecture\\nimproves the graph classification performance compared to the baseline\\narchitectures. In addition, analyses on the layer-wise graph representations\\nsuggest that aggregating information from multiple levels of localities indeed\\nhas the potential to improve the discriminability of learned graph\\nrepresentations.\",\n",
       " 'Deep networks and decision forests (such as random forests and gradient\\nboosted trees) are the leading machine learning methods for structured and\\ntabular data, respectively. Many papers have empirically compared large numbers\\nof classifiers on one or two different domains (e.g., on 100 different tabular\\ndata settings). However, a careful conceptual and empirical comparison of these\\ntwo strategies using the most contemporary best practices has yet to be\\nperformed. Conceptually, we illustrate that both can be profitably viewed as\\n\"partition and vote\" schemes. Specifically, the representation space that they\\nboth learn is a partitioning of feature space into a union of convex polytopes.\\nFor inference, each decides on the basis of votes from the activated nodes.\\nThis formulation allows for a unified basic understanding of the relationship\\nbetween these methods. Empirically, we compare these two strategies on hundreds\\nof tabular data settings, as well as several vision and auditory settings. Our\\nfocus is on datasets with at most 10,000 samples, which represent a large\\nfraction of scientific and biomedical datasets. In general, we found forests to\\nexcel at tabular and structured data (vision and audition) with small sample\\nsizes, whereas deep nets performed better on structured data with larger sample\\nsizes. This suggests that further gains in both scenarios may be realized via\\nfurther combining aspects of forests and networks. We will continue revising\\nthis technical report in the coming months with updated results.',\n",
       " 'Graph convolutional networks (GCNs) are powerful tools for graph-structured\\ndata. However, they have been recently shown to be vulnerable to topological\\nattacks. To enhance adversarial robustness, we go beyond spectral graph theory\\nto robust graph theory. By challenging the classical graph Laplacian, we\\npropose a new convolution operator that is provably robust in the spectral\\ndomain and is incorporated in the GCN architecture to improve expressivity and\\ninterpretability. By extending the original graph to a sequence of graphs, we\\nalso propose a robust training paradigm that encourages transferability across\\ngraphs that span a range of spatial and spectral characteristics. The proposed\\napproaches are demonstrated in extensive experiments to simultaneously improve\\nperformance in both benign and adversarial situations.',\n",
       " 'With the increasing popularity of Graph Neural Networks (GNNs) in several\\nsensitive applications like healthcare and medicine, concerns have been raised\\nover the privacy aspects of trained GNNs. More notably, GNNs are vulnerable to\\nprivacy attacks, such as membership inference attacks, even if only blackbox\\naccess to the trained model is granted. To build defenses, differential privacy\\nhas emerged as a mechanism to disguise the sensitive data in training datasets.\\nFollowing the strategy of Private Aggregation of Teacher Ensembles (PATE),\\nrecent methods leverage a large ensemble of teacher models. These teachers are\\ntrained on disjoint subsets of private data and are employed to transfer\\nknowledge to a student model, which is then released with privacy guarantees.\\nHowever, splitting graph data into many disjoint training sets may destroy the\\nstructural information and adversely affect accuracy. We propose a new\\ngraph-specific scheme of releasing a student GNN, which avoids splitting\\nprivate training data altogether. The student GNN is trained using public data,\\npartly labeled privately using the teacher GNN models trained exclusively for\\neach query node. We theoretically analyze our approach in the R\\\\`{e}nyi\\ndifferential privacy framework and provide privacy guarantees. Besides, we show\\nthe solid experimental performance of our method compared to several baselines,\\nincluding the PATE baseline adapted for graph-structured data. Our anonymized\\ncode is available.',\n",
       " 'Machine learning solutions for pattern classification problems are nowadays\\nwidely deployed in society and industry. However, the lack of transparency and\\naccountability of most accurate models often hinders their safe use. Thus,\\nthere is a clear need for developing explainable artificial intelligence\\nmechanisms. There exist model-agnostic methods that summarize feature\\ncontributions, but their interpretability is limited to predictions made by\\nblack-box models. An open challenge is to develop models that have intrinsic\\ninterpretability and produce their own explanations, even for classes of models\\nthat are traditionally considered black boxes like (recurrent) neural networks.\\nIn this paper, we propose a Long-Term Cognitive Network for interpretable\\npattern classification of structured data. Our method brings its own mechanism\\nfor providing explanations by quantifying the relevance of each feature in the\\ndecision process. For supporting the interpretability without affecting the\\nperformance, the model incorporates more flexibility through a quasi-nonlinear\\nreasoning rule that allows controlling nonlinearity. Besides, we propose a\\nrecurrence-aware decision model that evades the issues posed by unique fixed\\npoints while introducing a deterministic learning method to compute the tunable\\nparameters. The simulations show that our interpretable model obtains\\ncompetitive results when compared to the state-of-the-art white and black-box\\nmodels.',\n",
       " 'Graph neural networks (GNNs) are powerful models for many graph-structured\\ntasks. Existing models often assume that a complete structure of a graph is\\navailable during training, however, in practice, graph-structured data is\\nusually formed in a streaming fashion, so that learning a graph continuously is\\noften necessary. In this paper, we aim to bridge GNN to lifelong learning by\\nconverting a graph problem to a regular learning problem, so that GNN is able\\nto inherit the lifelong learning techniques developed for convolutional neural\\nnetworks (CNNs). To this end, we propose a new graph topology based on feature\\ncross-correlation, called the feature graph. It takes features as new nodes and\\nturns nodes into independent graphs. This successfully converts the original\\nproblem of node classification to graph classification, in which the increasing\\nnodes are turned into independent training samples. In the experiments, we\\ndemonstrate the efficiency and effectiveness of feature graph networks (FGN) by\\ncontinuously learning a sequence of classical graph datasets. We also show that\\nFGN achieves superior performance in human action recognition with distributed\\nstreaming signals for wearable devices.',\n",
       " 'Deep learning models, such as convolutional neural networks, have long been\\napplied to image and multi-media tasks, particularly those with structured\\ndata. More recently, there has been more attention to unstructured data that\\ncan be represented via graphs. These types of data are often found in health\\nand medicine, social networks, and research data repositories. Graph\\nconvolutional neural networks have recently gained attention in the field of\\ndeep learning that takes advantage of graph-based data representation with\\nautomatic feature extraction via convolutions. Given the popularity of these\\nmethods in a wide range of applications, robust uncertainty quantification is\\nvital. This remains a challenge for large models and unstructured datasets.\\nBayesian inference provides a principled approach to uncertainty quantification\\nof model parameters for deep learning models. Although Bayesian inference has\\nbeen used extensively elsewhere, its application to deep learning remains\\nlimited due to the computational requirements of the Markov Chain Monte Carlo\\n(MCMC) methods. Recent advances in parallel computing and advanced proposal\\nschemes in MCMC sampling methods has opened the path for Bayesian deep\\nlearning. In this paper, we present Bayesian graph convolutional neural\\nnetworks that employ tempered MCMC sampling with Langevin-gradient proposal\\ndistribution implemented via parallel computing. Our results show that the\\nproposed method can provide accuracy similar to advanced optimisers while\\nproviding uncertainty quantification for key benchmark problems.',\n",
       " \"A Graph Convolutional Network (GCN) stacks several layers and in each layer\\nperforms a PROPagation operation (PROP) and a TRANsformation operation (TRAN)\\nfor learning node representations over graph-structured data. Though powerful,\\nGCNs tend to suffer performance drop when the model gets deep. Previous works\\nfocus on PROPs to study and mitigate this issue, but the role of TRANs is\\nbarely investigated. In this work, we study performance degradation of GCNs by\\nexperimentally examining how stacking only TRANs or PROPs works. We find that\\nTRANs contribute significantly, or even more than PROPs, to declining\\nperformance, and moreover that they tend to amplify node-wise feature variance\\nin GCNs, causing variance inflammation that we identify as a key factor for\\ncausing performance drop. Motivated by such observations, we propose a\\nvariance-controlling technique termed Node Normalization (NodeNorm), which\\nscales each node's features using its own standard deviation. Experimental\\nresults validate the effectiveness of NodeNorm on addressing performance\\ndegradation of GCNs. Specifically, it enables deep GCNs to outperform shallow\\nones in cases where deep models are needed, and to achieve comparable results\\nwith shallow ones on 6 benchmark datasets. NodeNorm is a generic plug-in and\\ncan well generalize to other GNN architectures. Code is publicly available at\\nhttps://github.com/miafei/NodeNorm.\",\n",
       " 'Transformer neural networks have achieved state-of-the-art results for\\nunstructured data such as text and images but their adoption for\\ngraph-structured data has been limited. This is partly due to the difficulty of\\nincorporating complex structural information in the basic transformer\\nframework. We propose a simple yet powerful extension to the transformer -\\nresidual edge channels. The resultant framework, which we call Edge-augmented\\nGraph Transformer (EGT), can directly accept, process and output structural\\ninformation as well as node information. It allows us to use global\\nself-attention, the key element of transformers, directly for graphs and comes\\nwith the benefit of long-range interaction among nodes. Moreover, the edge\\nchannels allow the structural information to evolve from layer to layer, and\\nprediction tasks on edges/links can be performed directly from the output\\nembeddings of these channels. In addition, we introduce a generalized\\npositional encoding scheme for graphs based on Singular Value Decomposition\\nwhich can improve the performance of EGT. Our framework, which relies on global\\nnode feature aggregation, achieves better performance compared to\\nConvolutional/Message-Passing Graph Neural Networks, which rely on local\\nfeature aggregation within a neighborhood. We verify the performance of EGT in\\na supervised learning setting on a wide range of experiments on benchmark\\ndatasets. Our findings indicate that convolutional aggregation is not an\\nessential inductive bias for graphs and global self-attention can serve as a\\nflexible and adaptive alternative.',\n",
       " 'Link prediction is one of the key problems for graph-structured data. With\\nthe advancement of graph neural networks, graph autoencoders (GAEs) and\\nvariational graph autoencoders (VGAEs) have been proposed to learn graph\\nembeddings in an unsupervised way. It has been shown that these methods are\\neffective for link prediction tasks. However, they do not work well in link\\npredictions when a node whose degree is zero (i.g., isolated node) is involved.\\nWe have found that GAEs/VGAEs make embeddings of isolated nodes close to zero\\nregardless of their content features. In this paper, we propose a novel\\nVariational Graph Normalized AutoEncoder (VGNAE) that utilize L2-normalization\\nto derive better embeddings for isolated nodes. We show that our VGNAEs\\noutperform the existing state-of-the-art models for link prediction tasks. The\\ncode is available at https://github.com/SeongJinAhn/VGNAE.',\n",
       " \"Data augmentation has been widely used in image data and linguistic data but\\nremains under-explored on graph-structured data. Existing methods focus on\\naugmenting the graph data from a global perspective and largely fall into two\\ngenres: structural manipulation and adversarial training with feature noise\\ninjection. However, the structural manipulation approach suffers information\\nloss issues while the adversarial training approach may downgrade the feature\\nquality by injecting noise. In this work, we introduce the local augmentation,\\nwhich enhances node features by its local subgraph structures. Specifically, we\\nmodel the data argumentation as a feature generation process. Given the central\\nnode's feature, our local augmentation approach learns the conditional\\ndistribution of its neighbors' features and generates the neighbors' optimal\\nfeature to boost the performance of downstream tasks. Based on the local\\naugmentation, we further design a novel framework: LA-GNN, which can apply to\\nany GNN models in a plug-and-play manner. Extensive experiments and analyses\\nshow that local augmentation consistently yields performance improvement for\\nvarious GNN architectures across a diverse set of benchmarks. Code is available\\nat https://github.com/Soughing0823/LAGNN.\",\n",
       " 'Graph Neural Network (GNN) research is rapidly growing thanks to the capacity\\nof GNNs in learning distributed representations from graph-structured data.\\nHowever, centralizing a massive amount of real-world graph data for GNN\\ntraining is prohibitive due to privacy concerns, regulation restrictions, and\\ncommercial competitions. Federated learning (FL), a trending distributed\\nlearning paradigm, provides possibilities to solve this challenge while\\npreserving data privacy. Despite recent advances in vision and language\\ndomains, there is no suitable platform for the FL of GNNs. To this end, we\\nintroduce FedGraphNN, an open FL benchmark system that can facilitate research\\non federated GNNs. FedGraphNN is built on a unified formulation of graph FL and\\ncontains a wide range of datasets from different domains, popular GNN models,\\nand FL algorithms, with secure and efficient system support. Particularly for\\nthe datasets, we collect, preprocess, and partition 36 datasets from 7 domains,\\nincluding both publicly available ones and specifically obtained ones such as\\nhERG and Tencent. Our empirical analysis showcases the utility of our benchmark\\nsystem, while exposing significant challenges in graph FL: federated GNNs\\nperform worse in most datasets with a non-IID split than centralized GNNs; the\\nGNN model that attains the best result in the centralized setting may not\\nmaintain its advantage in the FL setting. These results imply that more\\nresearch efforts are needed to unravel the mystery behind federated GNNs.\\nMoreover, our system performance analysis demonstrates that the FedGraphNN\\nsystem is computationally efficient and secure to large-scale graphs datasets.\\nWe maintain the source code at https://github.com/FedML-AI/FedGraphNN.',\n",
       " 'Interpreting deep neural networks from the ordinary differential equations\\n(ODEs) perspective has inspired many efficient and robust network\\narchitectures. However, existing ODE based approaches ignore the relationship\\namong data points, which is a critical component in many problems including\\nfew-shot learning and semi-supervised learning. In this paper, inspired by the\\ndiffusive ODEs, we propose a novel diffusion residual network (Diff-ResNet) to\\nstrengthen the interactions among data points. Under the structured data\\nassumption, it is proved that the diffusion mechanism can decrease the\\ndistance-diameter ratio that improves the separability of inter-class points\\nand reduces the distance among local intra-class points. This property can be\\neasily adopted by the residual networks for constructing the separable\\nhyperplanes. The synthetic binary classification experiments demonstrate the\\neffectiveness of the proposed diffusion mechanism. Moreover, extensive\\nexperiments of few-shot image classification and semi-supervised graph node\\nclassification in various datasets validate the advantages of the proposed\\nDiff-ResNet over existing few-shot learning methods.',\n",
       " 'The success of machine learning stems from its structured data\\nrepresentation. Similar data have close representation as compressed codes for\\nclassification or emerged labels for clustering. We observe that the frequency\\nof the internal representation follows power laws in both supervised and\\nunsupervised learning. The scale-invariant distribution implies that machine\\nlearning largely compresses frequent typical data, and at the same time,\\ndifferentiates many atypical data as outliers. In this study, we derive how the\\npower laws can naturally arise in machine learning. In terms of information\\ntheory, the scale-invariant representation corresponds to a maximally uncertain\\ndata grouping among possible representations that guarantee pre-specified\\nlearning accuracy.',\n",
       " 'Sensitive medical data is often subject to strict usage constraints. In this\\npaper, we trained a generative adversarial network (GAN) on real-world\\nelectronic health records (EHR). It was then used to create a data-set of\\n\"fake\" patients through synthetic data generation (SDG) to circumvent usage\\nconstraints. This real-world data was tabular, binary, intensive care unit\\n(ICU) patient diagnosis data. The entire data-set was split into separate data\\nsilos to mimic real-world scenarios where multiple ICU units across different\\nhospitals may have similarly structured data-sets within their own\\norganisations but do not have access to each other\\'s data-sets. We implemented\\nfederated learning (FL) to train separate GANs locally at each organisation,\\nusing their unique data silo and then combining the GANs into a single central\\nGAN, without any siloed data ever being exposed. This global, central GAN was\\nthen used to generate the synthetic patients data-set. We performed an\\nevaluation of these synthetic patients with statistical measures and through a\\nstructured review by a group of medical professionals. It was shown that there\\nwas no significant reduction in the quality of the synthetic EHR when we moved\\nbetween training a single central model and training on separate data silos\\nwith individual models before combining them into a central model. This was\\ntrue for both the statistical evaluation (Root Mean Square Error (RMSE) of\\n0.0154 for single-source vs. RMSE of 0.0169 for dual-source federated) and also\\nfor the medical professionals\\' evaluation (no quality difference between EHR\\ngenerated from a single source and EHR generated from multiple sources).',\n",
       " 'Message-Passing Neural Networks (MPNNs), the most prominent Graph Neural\\nNetwork (GNN) framework, celebrate much success in the analysis of\\ngraph-structured data. Concurrently, the sparsification of Neural Network\\nmodels attracts a great amount of academic and industrial interest. In this\\npaper, we conduct a structured study of the effect of sparsification on the\\ntrainable part of MPNNs known as the Update step. To this end, we design a\\nseries of models to successively sparsify the linear transform in the Update\\nstep. Specifically, we propose the ExpanderGNN model with a tuneable\\nsparsification rate and the Activation-Only GNN, which has no linear transform\\nin the Update step. In agreement with a growing trend in the literature, the\\nsparsification paradigm is changed by initialising sparse neural network\\narchitectures rather than expensively sparsifying already trained\\narchitectures. Our novel benchmark models enable a better understanding of the\\ninfluence of the Update step on model performance and outperform existing\\nsimplified benchmark models such as the Simple Graph Convolution. The\\nExpanderGNNs, and in some cases the Activation-Only models, achieve performance\\non par with their vanilla counterparts on several downstream tasks while\\ncontaining significantly fewer trainable parameters. In experiments with\\nmatching parameter numbers, our benchmark models outperform the\\nstate-of-the-art GNN models. Our code is publicly available at:\\nhttps://github.com/ChangminWu/ExpanderGNN.',\n",
       " \"Graph feature extraction is a fundamental task in graphs analytics. Using\\nfeature vectors (graph descriptors) in tandem with data mining algorithms that\\noperate on Euclidean data, one can solve problems such as classification,\\nclustering, and anomaly detection on graph-structured data. This idea has\\nproved fruitful in the past, with spectral-based graph descriptors providing\\nstate-of-the-art classification accuracy on benchmark datasets. However, these\\nalgorithms do not scale to large graphs since: 1) they require storing the\\nentire graph in memory, and 2) the end-user has no control over the algorithm's\\nruntime. In this paper, we present single-pass streaming algorithms to\\napproximate structural features of graphs (counts of subgraphs of order $k \\\\geq\\n4$). Operating on edge streams allows us to avoid keeping the entire graph in\\nmemory, and controlling the sample size enables us to control the time taken by\\nthe algorithm. We demonstrate the efficacy of our descriptors by analyzing the\\napproximation error, classification accuracy, and scalability to massive\\ngraphs. Our experiments showcase the effect of the sample size on approximation\\nerror and predictive accuracy. The proposed descriptors are applicable on\\ngraphs with millions of edges within minutes and outperform the\\nstate-of-the-art descriptors in classification accuracy.\",\n",
       " 'Networks are ubiquitous in the real world such as social networks and\\ncommunication networks, and anomaly detection on networks aims at finding nodes\\nwhose structural or attributed patterns deviate significantly from the majority\\nof reference nodes. However, most of the traditional anomaly detection methods\\nneglect the relation structure information among data points and therefore\\ncannot effectively generalize to the graph structure data. In this paper, we\\npropose an end-to-end model of Deep Dual Support Vector Data description based\\nAutoencoder (Dual-SVDAE) for anomaly detection on attributed networks, which\\nconsiders both the structure and attribute for attributed networks.\\nSpecifically, Dual-SVDAE consists of a structure autoencoder and an attribute\\nautoencoder to learn the latent representation of the node in the structure\\nspace and attribute space respectively. Then, a dual-hypersphere learning\\nmechanism is imposed on them to learn two hyperspheres of normal nodes from the\\nstructure and attribute perspectives respectively. Moreover, to achieve joint\\nlearning between the structure and attribute of the network, we fuse the\\nstructure embedding and attribute embedding as the final input of the feature\\ndecoder to generate the node attribute. Finally, abnormal nodes can be detected\\nby measuring the distance of nodes to the learned center of each hypersphere in\\nthe latent structure space and attribute space respectively. Extensive\\nexperiments on the real-world attributed networks show that Dual-SVDAE\\nconsistently outperforms the state-of-the-arts, which demonstrates the\\neffectiveness of the proposed method.',\n",
       " 'Graph neural networks (GNNs) have shown great power in modeling graph\\nstructured data. However, similar to other machine learning models, GNNs may\\nmake biased predictions w.r.t protected sensitive attributes, e.g., skin color\\nand gender. This is because the training data often contains historical bias\\ntowards sensitive attributes. In addition, we empirically show that the\\ndiscrimination in GNNs can be magnified by graph structures and the\\nmessage-passing mechanism of GNNs. As a result, the applications of GNNs in\\nhigh-stake domains such as crime rate prediction would be largely limited.\\nThough extensive studies of fair classification have been conducted on i.i.d\\ndata, methods to address the problem of discrimination on non-i.i.d data are\\nrather limited. Generally, learning fair models require abundant sensitive\\nattributes to regularize the model. However, for many graphs such as social\\nnetworks, users are reluctant to share sensitive attributes. Thus, only limited\\nsensitive attributes are available for fair GNN training in practice. Moreover,\\ndirectly collecting and applying the sensitive attributes in fair model\\ntraining may cause privacy issues, because the sensitive information can be\\nleaked in data breach or attacks on the trained model. Therefore, we study a\\nnovel and crucial problem of learning fair GNNs with limited and private\\nsensitive attribute information. In an attempt to address these problems,\\nFairGNN is proposed to eliminate the bias of GNNs whilst maintaining high\\naccuracy by leveraging graph structures and limited sensitive information. We\\nfurther extend FairGNN to NT-FairGNN which can achieve both fairness and\\nprivacy on sensitive attributes by using limited and private sensitive\\nattributes. Theoretical analysis and extensive experiments on real-world\\ndatasets demonstrate the effectiveness of FairGNN and NT-FairGNN in achieving\\nfair and high-accurate classification.',\n",
       " 'Learning distributions over graph-structured data is a challenging task with\\nmany applications in biology and chemistry. In this work we use an energy-based\\nmodel (EBM) based on multi-channel graph neural networks (GNN) to learn\\npermutation invariant unnormalized density functions on graphs. Unlike standard\\nEBM training methods our approach is to learn the model via minimizing\\nadversarial stein discrepancy. Samples from the model can be obtained via\\nLangevin dynamics based MCMC. We find that this approach achieves competitive\\nresults on graph generation compared to benchmark models.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d13ab1c",
   "metadata": {},
   "source": [
    "# Data exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9aa997d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:40.217665Z",
     "start_time": "2023-05-08T00:07:40.190689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56181 entries, 0 to 56180\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   terms      56181 non-null  object\n",
      " 1   titles     56181 non-null  object\n",
      " 2   abstracts  56181 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bd3ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:40.221564Z",
     "start_time": "2023-05-08T00:07:40.219228Z"
    }
   },
   "outputs": [],
   "source": [
    "#histogram of lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5839fd18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:40.234953Z",
     "start_time": "2023-05-08T00:07:40.223027Z"
    }
   },
   "outputs": [],
   "source": [
    "abstract_lengths = [len(item) for item in df['abstracts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c934fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:40.385275Z",
     "start_time": "2023-05-08T00:07:40.236040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.StepPatch at 0x7fa9c29e00d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts, edges = np.histogram(abstract_lengths, bins=50)\n",
    "plt.stairs(counts, edges, fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b93858a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:40.389106Z",
     "start_time": "2023-05-08T00:07:40.387286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Topic modeling (use existing libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eff341e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:40.399869Z",
     "start_time": "2023-05-08T00:07:40.390138Z"
    }
   },
   "outputs": [],
   "source": [
    "no_features = 1000 # This is the number of different words to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c66a9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:40.403537Z",
     "start_time": "2023-05-08T00:07:40.401098Z"
    }
   },
   "outputs": [],
   "source": [
    "# LDA uses raw term counts \n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, \n",
    "                                min_df=2, \n",
    "                                max_features = no_features, \n",
    "                                stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c31a8644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:44.490836Z",
     "start_time": "2023-05-08T00:07:40.404540Z"
    }
   },
   "outputs": [],
   "source": [
    "tf = tf_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a5ad1d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:44.496071Z",
     "start_time": "2023-05-08T00:07:44.492184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gino/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee4093e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:44.507331Z",
     "start_time": "2023-05-08T00:07:44.497246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<56181x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3051538 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff9b152f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:07:44.519574Z",
     "start_time": "2023-05-08T00:07:44.508691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '2d',\n",
       " '3d',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adaptive',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'advances',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adversarial',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'aggregation',\n",
       " 'ai',\n",
       " 'aim',\n",
       " 'aims',\n",
       " 'al',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'alignment',\n",
       " 'allow',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alternative',\n",
       " 'analysis',\n",
       " 'analyze',\n",
       " 'annotated',\n",
       " 'annotation',\n",
       " 'annotations',\n",
       " 'anomaly',\n",
       " 'appearance',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'approach',\n",
       " 'approaches',\n",
       " 'approximate',\n",
       " 'approximation',\n",
       " 'arbitrary',\n",
       " 'architecture',\n",
       " 'architectures',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'art',\n",
       " 'artificial',\n",
       " 'aspects',\n",
       " 'associated',\n",
       " 'attack',\n",
       " 'attacks',\n",
       " 'attention',\n",
       " 'attribute',\n",
       " 'attributes',\n",
       " 'augmentation',\n",
       " 'augmented',\n",
       " 'auto',\n",
       " 'autoencoder',\n",
       " 'automated',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'autonomous',\n",
       " 'auxiliary',\n",
       " 'available',\n",
       " 'average',\n",
       " 'aware',\n",
       " 'background',\n",
       " 'based',\n",
       " 'baseline',\n",
       " 'baselines',\n",
       " 'batch',\n",
       " 'bayesian',\n",
       " 'behavior',\n",
       " 'benchmark',\n",
       " 'benchmarks',\n",
       " 'benefits',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bias',\n",
       " 'binary',\n",
       " 'black',\n",
       " 'block',\n",
       " 'body',\n",
       " 'bound',\n",
       " 'boundary',\n",
       " 'bounding',\n",
       " 'bounds',\n",
       " 'box',\n",
       " 'boxes',\n",
       " 'brain',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'called',\n",
       " 'camera',\n",
       " 'cameras',\n",
       " 'capability',\n",
       " 'capable',\n",
       " 'captioning',\n",
       " 'capture',\n",
       " 'captured',\n",
       " 'capturing',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'categories',\n",
       " 'category',\n",
       " 'causal',\n",
       " 'certain',\n",
       " 'challenge',\n",
       " 'challenges',\n",
       " 'challenging',\n",
       " 'change',\n",
       " 'changes',\n",
       " 'channel',\n",
       " 'characteristics',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classical',\n",
       " 'classification',\n",
       " 'classifier',\n",
       " 'classifiers',\n",
       " 'clinical',\n",
       " 'cloud',\n",
       " 'clouds',\n",
       " 'clustering',\n",
       " 'cnn',\n",
       " 'cnns',\n",
       " 'coarse',\n",
       " 'coco',\n",
       " 'code',\n",
       " 'collected',\n",
       " 'color',\n",
       " 'com',\n",
       " 'combination',\n",
       " 'combine',\n",
       " 'combined',\n",
       " 'combines',\n",
       " 'combining',\n",
       " 'common',\n",
       " 'commonly',\n",
       " 'community',\n",
       " 'comparable',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparison',\n",
       " 'competitive',\n",
       " 'complete',\n",
       " 'complex',\n",
       " 'complexity',\n",
       " 'component',\n",
       " 'components',\n",
       " 'comprehensive',\n",
       " 'compression',\n",
       " 'computation',\n",
       " 'computational',\n",
       " 'computationally',\n",
       " 'compute',\n",
       " 'computer',\n",
       " 'computing',\n",
       " 'concept',\n",
       " 'concepts',\n",
       " 'conditional',\n",
       " 'conditions',\n",
       " 'conduct',\n",
       " 'conducted',\n",
       " 'connected',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consistency',\n",
       " 'consistent',\n",
       " 'consists',\n",
       " 'constrained',\n",
       " 'constraint',\n",
       " 'constraints',\n",
       " 'construct',\n",
       " 'contains',\n",
       " 'content',\n",
       " 'context',\n",
       " 'contextual',\n",
       " 'continuous',\n",
       " 'contrast',\n",
       " 'contrastive',\n",
       " 'contribution',\n",
       " 'control',\n",
       " 'conventional',\n",
       " 'convergence',\n",
       " 'convex',\n",
       " 'convolution',\n",
       " 'convolutional',\n",
       " 'core',\n",
       " 'correlation',\n",
       " 'corresponding',\n",
       " 'cost',\n",
       " 'create',\n",
       " 'critical',\n",
       " 'cross',\n",
       " 'crucial',\n",
       " 'current',\n",
       " 'data',\n",
       " 'database',\n",
       " 'dataset',\n",
       " 'datasets',\n",
       " 'decision',\n",
       " 'decoder',\n",
       " 'decomposition',\n",
       " 'deep',\n",
       " 'defined',\n",
       " 'demonstrate',\n",
       " 'demonstrated',\n",
       " 'demonstrates',\n",
       " 'dense',\n",
       " 'density',\n",
       " 'dependencies',\n",
       " 'dependent',\n",
       " 'depth',\n",
       " 'derive',\n",
       " 'derived',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'despite',\n",
       " 'details',\n",
       " 'detect',\n",
       " 'detecting',\n",
       " 'detection',\n",
       " 'detector',\n",
       " 'detectors',\n",
       " 'develop',\n",
       " 'developed',\n",
       " 'development',\n",
       " 'devices',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'differentiable',\n",
       " 'difficult',\n",
       " 'dimension',\n",
       " 'dimensional',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'discrete',\n",
       " 'discriminative',\n",
       " 'discriminator',\n",
       " 'discuss',\n",
       " 'disease',\n",
       " 'distance',\n",
       " 'distillation',\n",
       " 'distributed',\n",
       " 'distribution',\n",
       " 'distributions',\n",
       " 'diverse',\n",
       " 'diversity',\n",
       " 'dnn',\n",
       " 'dnns',\n",
       " 'does',\n",
       " 'domain',\n",
       " 'domains',\n",
       " 'downstream',\n",
       " 'driven',\n",
       " 'driving',\n",
       " 'dual',\n",
       " 'dynamic',\n",
       " 'dynamics',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'edge',\n",
       " 'edges',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effectively',\n",
       " 'effectiveness',\n",
       " 'effects',\n",
       " 'efficiency',\n",
       " 'efficient',\n",
       " 'efficiently',\n",
       " 'embedded',\n",
       " 'embedding',\n",
       " 'embeddings',\n",
       " 'empirical',\n",
       " 'empirically',\n",
       " 'employ',\n",
       " 'employed',\n",
       " 'enable',\n",
       " 'enables',\n",
       " 'encode',\n",
       " 'encoder',\n",
       " 'encoding',\n",
       " 'end',\n",
       " 'energy',\n",
       " 'enhance',\n",
       " 'ensemble',\n",
       " 'entire',\n",
       " 'entropy',\n",
       " 'environment',\n",
       " 'environments',\n",
       " 'error',\n",
       " 'errors',\n",
       " 'especially',\n",
       " 'essential',\n",
       " 'estimate',\n",
       " 'estimated',\n",
       " 'estimates',\n",
       " 'estimating',\n",
       " 'estimation',\n",
       " 'evaluate',\n",
       " 'evaluated',\n",
       " 'evaluation',\n",
       " 'event',\n",
       " 'events',\n",
       " 'example',\n",
       " 'examples',\n",
       " 'existing',\n",
       " 'expensive',\n",
       " 'experiment',\n",
       " 'experimental',\n",
       " 'experiments',\n",
       " 'expert',\n",
       " 'explain',\n",
       " 'explanations',\n",
       " 'explicit',\n",
       " 'explicitly',\n",
       " 'exploit',\n",
       " 'exploiting',\n",
       " 'exploration',\n",
       " 'explore',\n",
       " 'expression',\n",
       " 'extend',\n",
       " 'extensive',\n",
       " 'extract',\n",
       " 'extracted',\n",
       " 'extraction',\n",
       " 'face',\n",
       " 'faces',\n",
       " 'facial',\n",
       " 'facilitate',\n",
       " 'factor',\n",
       " 'factors',\n",
       " 'fail',\n",
       " 'far',\n",
       " 'fashion',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'field',\n",
       " 'fields',\n",
       " 'filter',\n",
       " 'filters',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'fixed',\n",
       " 'flexible',\n",
       " 'flow',\n",
       " 'focus',\n",
       " 'following',\n",
       " 'forecasting',\n",
       " 'form',\n",
       " 'formulation',\n",
       " 'forward',\n",
       " 'frame',\n",
       " 'frames',\n",
       " 'framework',\n",
       " 'free',\n",
       " 'frequency',\n",
       " 'fully',\n",
       " 'function',\n",
       " 'functions',\n",
       " 'fundamental',\n",
       " 'furthermore',\n",
       " 'fusion',\n",
       " 'future',\n",
       " 'game',\n",
       " 'games',\n",
       " 'gan',\n",
       " 'gans',\n",
       " 'gap',\n",
       " 'gaussian',\n",
       " 'gcn',\n",
       " 'general',\n",
       " 'generalization',\n",
       " 'generalize',\n",
       " 'generally',\n",
       " 'generate',\n",
       " 'generated',\n",
       " 'generates',\n",
       " 'generating',\n",
       " 'generation',\n",
       " 'generative',\n",
       " 'generator',\n",
       " 'generic',\n",
       " 'geometric',\n",
       " 'geometry',\n",
       " 'github',\n",
       " 'given',\n",
       " 'global',\n",
       " 'gnn',\n",
       " 'gnns',\n",
       " 'goal',\n",
       " 'good',\n",
       " 'gradient',\n",
       " 'grained',\n",
       " 'graph',\n",
       " 'graphical',\n",
       " 'graphs',\n",
       " 'great',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'guided',\n",
       " 'hand',\n",
       " 'handle',\n",
       " 'hard',\n",
       " 'head',\n",
       " 'help',\n",
       " 'heterogeneous',\n",
       " 'hidden',\n",
       " 'hierarchical',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highly',\n",
       " 'https',\n",
       " 'human',\n",
       " 'humans',\n",
       " 'hybrid',\n",
       " 'idea',\n",
       " 'identification',\n",
       " 'identify',\n",
       " 'ii',\n",
       " 'image',\n",
       " 'imagenet',\n",
       " 'images',\n",
       " 'imaging',\n",
       " 'impact',\n",
       " 'implementation',\n",
       " 'implicit',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'improves',\n",
       " 'improving',\n",
       " 'include',\n",
       " 'including',\n",
       " 'incorporate',\n",
       " 'increase',\n",
       " 'increasing',\n",
       " 'independent',\n",
       " 'individual',\n",
       " 'inference',\n",
       " 'information',\n",
       " 'initial',\n",
       " 'input',\n",
       " 'inputs',\n",
       " 'insights',\n",
       " 'inspired',\n",
       " 'instance',\n",
       " 'instances',\n",
       " 'instead',\n",
       " 'inter',\n",
       " 'interaction',\n",
       " 'interactions',\n",
       " 'interpretability',\n",
       " 'interpretable',\n",
       " 'introduce',\n",
       " 'introduced',\n",
       " 'introduces',\n",
       " 'introducing',\n",
       " 'invariant',\n",
       " 'inverse',\n",
       " 'investigate',\n",
       " 'issue',\n",
       " 'issues',\n",
       " 'iterative',\n",
       " 'joint',\n",
       " 'jointly',\n",
       " 'kernel',\n",
       " 'key',\n",
       " 'kitti',\n",
       " 'knowledge',\n",
       " 'known',\n",
       " 'label',\n",
       " 'labeled',\n",
       " 'labeling',\n",
       " 'labels',\n",
       " 'lack',\n",
       " 'language',\n",
       " 'large',\n",
       " 'larger',\n",
       " 'latent',\n",
       " 'layer',\n",
       " 'layers',\n",
       " 'lead',\n",
       " 'leading',\n",
       " 'leads',\n",
       " 'learn',\n",
       " 'learned',\n",
       " 'learning',\n",
       " 'learns',\n",
       " 'level',\n",
       " 'levels',\n",
       " 'leverage',\n",
       " 'leverages',\n",
       " 'leveraging',\n",
       " 'lidar',\n",
       " 'light',\n",
       " 'like',\n",
       " 'likelihood',\n",
       " 'limitations',\n",
       " 'limited',\n",
       " 'linear',\n",
       " 'literature',\n",
       " 'local',\n",
       " 'localization',\n",
       " 'location',\n",
       " 'long',\n",
       " 'loss',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'lstm',\n",
       " 'machine',\n",
       " 'main',\n",
       " 'mainly',\n",
       " 'major',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'manifold',\n",
       " 'manner',\n",
       " 'manual',\n",
       " 'map',\n",
       " 'mapping',\n",
       " 'maps',\n",
       " 'margin',\n",
       " 'markov',\n",
       " 'mask',\n",
       " 'matching',\n",
       " 'matrix',\n",
       " 'maximum',\n",
       " 'mean',\n",
       " 'meaningful',\n",
       " 'means',\n",
       " 'measure',\n",
       " 'measures',\n",
       " 'mechanism',\n",
       " 'mechanisms',\n",
       " 'medical',\n",
       " 'memory',\n",
       " 'meta',\n",
       " 'method',\n",
       " 'methods',\n",
       " 'metric',\n",
       " 'metrics',\n",
       " 'missing',\n",
       " 'ml',\n",
       " 'mobile',\n",
       " 'modal',\n",
       " 'modalities',\n",
       " 'modality',\n",
       " 'model',\n",
       " 'modeling',\n",
       " 'models',\n",
       " 'modern',\n",
       " 'module',\n",
       " 'modules',\n",
       " 'molecular',\n",
       " 'monocular',\n",
       " 'motion',\n",
       " 'motivated',\n",
       " 'moving',\n",
       " 'multi',\n",
       " 'multimodal',\n",
       " 'multiple',\n",
       " 'named',\n",
       " 'natural',\n",
       " 'nature',\n",
       " 'need',\n",
       " 'negative',\n",
       " 'net',\n",
       " 'network',\n",
       " 'networks',\n",
       " 'neural',\n",
       " 'new',\n",
       " 'node',\n",
       " 'nodes',\n",
       " 'noise',\n",
       " 'noisy',\n",
       " 'non',\n",
       " 'nonlinear',\n",
       " 'normal',\n",
       " 'novel',\n",
       " 'number',\n",
       " 'numerical',\n",
       " 'object',\n",
       " 'objective',\n",
       " 'objects',\n",
       " 'observation',\n",
       " 'observations',\n",
       " 'observed',\n",
       " 'obtain',\n",
       " 'obtained',\n",
       " 'ones',\n",
       " 'online',\n",
       " 'open',\n",
       " 'operation',\n",
       " 'operations',\n",
       " 'optical',\n",
       " 'optimal',\n",
       " 'optimization',\n",
       " 'optimize',\n",
       " 'optimized',\n",
       " 'order',\n",
       " 'original',\n",
       " 'outperform',\n",
       " 'outperforms',\n",
       " 'output',\n",
       " 'outputs',\n",
       " 'overall',\n",
       " 'overcome',\n",
       " 'pair',\n",
       " 'pairs',\n",
       " 'paper',\n",
       " 'paradigm',\n",
       " 'parameter',\n",
       " 'parameters',\n",
       " 'partial',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'parts',\n",
       " 'past',\n",
       " 'patch',\n",
       " 'patches',\n",
       " 'path',\n",
       " 'patterns',\n",
       " 'perception',\n",
       " 'perform',\n",
       " 'performance',\n",
       " 'performed',\n",
       " 'performing',\n",
       " 'performs',\n",
       " 'person',\n",
       " 'perspective',\n",
       " 'phase',\n",
       " 'physical',\n",
       " 'pipeline',\n",
       " 'pixel',\n",
       " 'pixels',\n",
       " 'planning',\n",
       " 'point',\n",
       " 'points',\n",
       " 'policies',\n",
       " 'policy',\n",
       " 'pooling',\n",
       " 'popular',\n",
       " 'pose',\n",
       " 'poses',\n",
       " 'position',\n",
       " 'positive',\n",
       " 'possible',\n",
       " 'potential',\n",
       " 'power',\n",
       " 'powerful',\n",
       " 'practical',\n",
       " 'practice',\n",
       " 'pre',\n",
       " 'precision',\n",
       " 'predict',\n",
       " 'predicted',\n",
       " 'predicting',\n",
       " 'prediction',\n",
       " 'predictions',\n",
       " 'predictive',\n",
       " 'present',\n",
       " 'presented',\n",
       " 'presents',\n",
       " 'preserving',\n",
       " 'previous',\n",
       " 'previously',\n",
       " 'prior',\n",
       " 'privacy',\n",
       " 'probabilistic',\n",
       " 'probability',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'procedure',\n",
       " 'process',\n",
       " 'processes',\n",
       " 'processing',\n",
       " 'produce',\n",
       " 'produces',\n",
       " 'progress',\n",
       " 'promising',\n",
       " 'propagation',\n",
       " 'properties',\n",
       " 'property',\n",
       " 'proposal',\n",
       " 'propose',\n",
       " 'proposed',\n",
       " 'proposes',\n",
       " 'prove',\n",
       " 'provide',\n",
       " 'provided',\n",
       " 'provides',\n",
       " 'providing',\n",
       " 'pruning',\n",
       " 'pseudo',\n",
       " 'public',\n",
       " 'publicly',\n",
       " 'purpose',\n",
       " 'qualitative',\n",
       " 'quality',\n",
       " 'quantitative',\n",
       " 'query',\n",
       " 'question',\n",
       " 'random',\n",
       " 'range',\n",
       " 'rank',\n",
       " 'rate',\n",
       " 'raw',\n",
       " 'real',\n",
       " 'realistic',\n",
       " 'reasoning',\n",
       " 'recent',\n",
       " 'recently',\n",
       " 'recognition',\n",
       " 'reconstruction',\n",
       " 'recurrent',\n",
       " 'reduce',\n",
       " 'reduces',\n",
       " 'reduction',\n",
       " 'reference',\n",
       " 'region',\n",
       " 'regions',\n",
       " 'registration',\n",
       " 'regression',\n",
       " 'regularization',\n",
       " 'reinforcement',\n",
       " 'related',\n",
       " 'relation',\n",
       " 'relations',\n",
       " 'relationship',\n",
       " 'relationships',\n",
       " 'relative',\n",
       " 'relevant',\n",
       " 'rely',\n",
       " 'remains',\n",
       " 'represent',\n",
       " 'representation',\n",
       " 'representations',\n",
       " 'require',\n",
       " 'required',\n",
       " 'requires',\n",
       " 'research',\n",
       " 'researchers',\n",
       " 'residual',\n",
       " 'resolution',\n",
       " 'respect',\n",
       " 'respectively',\n",
       " 'result',\n",
       " 'resulting',\n",
       " 'results',\n",
       " 'retrieval',\n",
       " 'reward',\n",
       " 'rewards',\n",
       " 'rgb',\n",
       " 'rich',\n",
       " 'risk',\n",
       " 'rl',\n",
       " 'road',\n",
       " 'robust',\n",
       " 'robustness',\n",
       " 'role',\n",
       " 'saliency',\n",
       " 'salient',\n",
       " 'sample',\n",
       " 'samples',\n",
       " 'sampling',\n",
       " 'scale',\n",
       " 'scales',\n",
       " 'scenarios',\n",
       " 'scene',\n",
       " 'scenes',\n",
       " 'scheme',\n",
       " 'score',\n",
       " 'scores',\n",
       " 'search',\n",
       " 'second',\n",
       " 'seen',\n",
       " 'segment',\n",
       " 'segmentation',\n",
       " 'selection',\n",
       " 'self',\n",
       " 'semantic',\n",
       " 'semi',\n",
       " 'sensing',\n",
       " 'sensitive',\n",
       " 'sensor',\n",
       " 'sensors',\n",
       " 'sequence',\n",
       " 'sequences',\n",
       " 'sequential',\n",
       " 'series',\n",
       " 'set',\n",
       " 'sets',\n",
       " 'setting',\n",
       " 'settings',\n",
       " 'shape',\n",
       " 'shapes',\n",
       " 'shared',\n",
       " 'short',\n",
       " 'shot',\n",
       " 'showing',\n",
       " 'shown',\n",
       " 'shows',\n",
       " 'signal',\n",
       " 'signals',\n",
       " 'significant',\n",
       " 'significantly',\n",
       " 'similar',\n",
       " 'similarity',\n",
       " 'simple',\n",
       " 'simulated',\n",
       " 'simulation',\n",
       " 'simultaneously',\n",
       " 'single',\n",
       " 'size',\n",
       " 'small',\n",
       " 'social',\n",
       " 'solution',\n",
       " 'solutions',\n",
       " 'solve',\n",
       " 'solving',\n",
       " 'source',\n",
       " 'space',\n",
       " 'spaces',\n",
       " 'sparse',\n",
       " 'spatial',\n",
       " 'spatio',\n",
       " 'specific',\n",
       " 'specifically',\n",
       " 'spectral',\n",
       " 'speed',\n",
       " 'sr',\n",
       " 'stage',\n",
       " 'standard',\n",
       " 'state',\n",
       " 'states',\n",
       " 'static',\n",
       " 'statistical',\n",
       " 'step',\n",
       " 'steps',\n",
       " 'stereo',\n",
       " 'stochastic',\n",
       " 'strategies',\n",
       " 'strategy',\n",
       " 'stream',\n",
       " 'strong',\n",
       " 'structural',\n",
       " 'structure',\n",
       " 'structured',\n",
       " 'structures',\n",
       " 'student',\n",
       " 'studied',\n",
       " 'studies',\n",
       " 'study',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'success',\n",
       " 'successful',\n",
       " 'successfully',\n",
       " 'suffer',\n",
       " 'suggest',\n",
       " 'suitable',\n",
       " 'super',\n",
       " 'superior',\n",
       " 'superiority',\n",
       " 'supervised',\n",
       " 'supervision',\n",
       " 'support',\n",
       " 'surface',\n",
       " 'synthesis',\n",
       " 'synthetic',\n",
       " 'systems',\n",
       " 'tackle',\n",
       " 'takes',\n",
       " 'target',\n",
       " 'task',\n",
       " 'tasks',\n",
       " 'teacher',\n",
       " 'technique',\n",
       " 'techniques',\n",
       " 'temporal',\n",
       " 'tensor',\n",
       " 'term',\n",
       " 'terms',\n",
       " 'test',\n",
       " 'tested',\n",
       " 'testing',\n",
       " 'text',\n",
       " 'texture',\n",
       " 'theoretical',\n",
       " 'theory',\n",
       " 'time',\n",
       " 'times',\n",
       " 'tool',\n",
       " 'tools',\n",
       " 'tracking',\n",
       " 'traditional',\n",
       " 'traffic',\n",
       " 'train',\n",
       " 'trained',\n",
       " 'training',\n",
       " 'trajectory',\n",
       " 'transfer',\n",
       " 'transform',\n",
       " 'transformation',\n",
       " 'transformations',\n",
       " 'transformer',\n",
       " 'transformers',\n",
       " 'translation',\n",
       " 'tree',\n",
       " 'trees',\n",
       " 'truth',\n",
       " 'tuning',\n",
       " 'type',\n",
       " 'types',\n",
       " 'typically',\n",
       " 'uncertainty',\n",
       " 'underlying',\n",
       " 'understand',\n",
       " 'understanding',\n",
       " 'unified',\n",
       " 'unknown',\n",
       " 'unlabeled',\n",
       " 'unlike',\n",
       " 'unseen',\n",
       " 'unsupervised',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'user',\n",
       " 'users',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'utilize',\n",
       " 'validate',\n",
       " 'value',\n",
       " 'values',\n",
       " 'variable',\n",
       " 'variables',\n",
       " 'variance',\n",
       " 'variational',\n",
       " 'variations',\n",
       " 'variety',\n",
       " 'various',\n",
       " 'varying',\n",
       " 'vector',\n",
       " 'vectors',\n",
       " 'vehicle',\n",
       " 'vehicles',\n",
       " 'video',\n",
       " 'videos',\n",
       " 'view',\n",
       " 'views',\n",
       " 'vision',\n",
       " 'visual',\n",
       " 'way',\n",
       " 'weakly',\n",
       " 'weight',\n",
       " 'weighted',\n",
       " 'weights',\n",
       " 'wide',\n",
       " 'widely',\n",
       " 'wise',\n",
       " 'work',\n",
       " 'works',\n",
       " 'world',\n",
       " 'years',\n",
       " 'yields',\n",
       " 'zero']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77540882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:09:06.899420Z",
     "start_time": "2023-05-08T00:07:44.521016Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "no_topics = 20\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, \n",
    "                                max_iter=5, \n",
    "                                learning_method='online', \n",
    "                                learning_offset=50.,\n",
    "                                random_state=0).fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "634891b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:09:06.904084Z",
     "start_time": "2023-05-08T00:09:06.900733Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()\\\n",
    "                        [:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "524469a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:09:06.919637Z",
     "start_time": "2023-05-08T00:09:06.905286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "3d object point detection depth scene objects cloud shape clouds\n",
      "Topic 1:\n",
      "data time based series detection using model method proposed used\n",
      "Topic 2:\n",
      "graph networks neural graphs network node nodes convolutional structure gnns\n",
      "Topic 3:\n",
      "learning deep models methods machine based research algorithms recent performance\n",
      "Topic 4:\n",
      "algorithm algorithms gradient method based matrix convergence sample model local\n",
      "Topic 5:\n",
      "model models generation image generative text visual language gans generate\n",
      "Topic 6:\n",
      "learning supervised unsupervised representations representation self data tasks semi supervision\n",
      "Topic 7:\n",
      "network neural networks model accuracy deep performance training architecture time\n",
      "Topic 8:\n",
      "real world estimation model data approach synthetic graphical uncertainty estimate\n",
      "Topic 9:\n",
      "attention task tasks transfer transformer fine pre trained classification training\n",
      "Topic 10:\n",
      "image images segmentation resolution method network color proposed results using\n",
      "Topic 11:\n",
      "data training domain learning model datasets class label target performance\n",
      "Topic 12:\n",
      "available code https github com driving autonomous meta publicly source\n",
      "Topic 13:\n",
      "search sampling optimization constraints set problem large tree approach inference\n",
      "Topic 14:\n",
      "reinforcement face policy rl agent action facial agents control environment\n",
      "Topic 15:\n",
      "video temporal motion flow videos fusion frames frame tracking optical\n",
      "Topic 16:\n",
      "features feature information attention multi propose methods proposed state art\n",
      "Topic 17:\n",
      "space latent data distribution dimensional model variables distance high distributions\n",
      "Topic 18:\n",
      "adversarial gan generative robustness networks noise training regularization attacks generator\n",
      "Topic 19:\n",
      "problem function learning problems functions theoretical analysis results framework loss\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14140f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gino_venv",
   "language": "python",
   "name": "gino_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
